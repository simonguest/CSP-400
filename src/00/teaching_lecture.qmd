---
title: "Introducing AI Agents"
format: 
  revealjs:
    incremental: true
    center-title-slide: true
    theme: default
logo: DigiPen_RGB_Red.jpg
---

# Recap of Last Lecture 

## Recap of Last Lecture

We used the OpenAI SDK to build our first AI-powered chatbot!

::: {.fragment}
- Screenshot of the chatbot interface
:::

## What Did We Learn?

::: {.incremental}
- How to use OpenAI API and SDK
- Context windows and conversation structure
- Available models, features, and costs
:::

## But We Discovered Limitations

Our simple chatbot had several...

- No ability to plan beyond a single interaction
- Needs constant human input every turn
- Cannot respond to different conditions
- Everything has to be replayed in the context window
- Cannot reach out to other LLMs and external systems

# How can Agents solve this?

## What is an Agent?

- Screenshot of all the media headlines to go here

## Five Characteristics of Agents

Imagine a DigiPen Campus Assistant...

- "Can you tell me more about FLM201?"
- "Where can I find the 'Hopper' room?"
- "Oh, and what's today's vegetarian option at the Bytes Cafe?"

## Five Characteristics of Agents

1. Agents are **Proactive**

- Agents are driven by goals
- And they can put together a plan for the steps to complete that goal.
  - "First, I will discover where course information is located"
  - "Then I will search for any courses that reference FLM201"
  - "Then I summarize all of the key points for the student"

## Five Characterisics of Agents

2. Agents are **Autonomous**

- Agents can then go off and execute the plan, independent of human input
- The concept of "human in the loop" still applies for confirmation
  - e.g. "Do you really want to place this order at the Bytes Cafe?"

## Five Characterisics of Agents

3. Agents are **Reactive**

- Agents can change mid-course depending on what they find and/or the environment.
  - e.g. "I couldn't find any course information on FLM201. I'm going to whether there are other 200-level FLM courses before responding to the student."

## Five Characterisics of Agents

4. Agents have **Persistence**

- Agents often have memory systems beyond the current conversation
- Broadly classified as short and long term memory 
  - Short term memory could be the options at the Bytes Cafe
  - Long term memory could be your food preferences

## Five Characterisics of Agents

5. Agents are **Interactive**

- Agents can delegate to other agents for complex tasks
  - (Or for tasks where other agents are better suited for.)
  - e.g., Campus Assistant -> delegating to a Course Agent
- Agents can also be given access to external tools
  - e.g., File search, Web search, access to the Bytes Cafe API

# Let's Try This!

## Let's Try This!

(QR Code to go here - 5 min activity)

## Oberservations and Questions

Get into groups of 2 or 3

Q: What worked? What surprised you?
Q: What didn't work? Where did the agent fail?
Q: What other examples of agents can you think of?

## Other Examples for Agents

- Customer service agent
- Travel booking agent
- Research assistant
- Code generation agent (very popular right now)
- Agents within games
  - Traditional NPCs are pre-written dialogue trees
  - Whereas agents can be more independent within the game environment

# How does the Campus Assistant work?

## Agent Handoffs

(Diagram of agent handoffs)

## How about the UI?

(Sidebar on Gradio)

# Creating Your First Agent

## So many agent frameworks...

(Diagram here)

## The popular ones

(Table here)

## What should you be considering?

- Where will your agent run?
  - Server or client? On the web? In game?
  - This will likely determine the language
  - How will you manage API keys?
- Support
  - Will this agent framework be around in 3-5 years?
  - Is there a cost/hosting component to it?
- Easy vs. Simple
  - Is your choice "easy" or "simple"?

## Sidebar: Easy vs. Simple

- Details here

## OpenAI Agents SDK (Python)

Creating and running a new agent

```{.python code-line-numbers="|1|3-8|9|10"}
from agents import Agent, Runner

agent = Agent(
    name="DigiPen Campus Assistant",
    instructions="You are a helpful campus assistant that can plan and execute tasks for students at DigiPen. Please be concise and accurate in handing off tasks to other agents as needed.",
    handoffs=[building_agent, course_agent, handbook_agent, cafe_agent],
)

messages.append({"role": "user", "content": user_msg})
result = Runner.run_streamed(agent, messages)
```

# Multiple Agents

## OpenAI Agents SDK (Python)

Specifying handoffs

```{.python code-line-numbers="|6"}
from agents import Agent, Runner

agent = Agent(
    name="DigiPen Campus Assistant",
    instructions="You are a helpful campus assistant that can plan and execute tasks for students at DigiPen. Please be concise and accurate in handing off tasks to other agents as needed.",
    handoffs=[building_agent, course_agent, handbook_agent, cafe_agent],
)

messages.append({"role": "user", "content": user_msg})
result = Runner.run_streamed(agent, messages)
```

## Why Multiple Agents?

- Context window limitations
- Each agent can have a different system prompt (instructions)
- Each agent can have a different underlying model
  - Specialized models (e.g., a vision encoder)
  - Or to blend cost
- Makes tool separation cleaner and more accurate

## Example of Multiple Agents

- Code generation
  - Agents for 'architect', code writer, tester, debugger, etc.
- Content generation
  - Agent to create content, other agents to generate images, translate content, etc.
- TBD - one more example

## Patterns for Agents

- As you get deeper into building agents, patterns start to emerge
  - e.g., router (which is what we used in our demo), orchestrator (using other agents as tools), parallel agents
- https://www.anthropic.com/engineering/building-effective-agents

# Providing Agents Access to Tools

## Why are tools needed?

- The scope of the agents ability is contained within the model
- Tools enable the agent to reach out to systems beyond the model
- Examples
  - Read a file from disk
  - Search the web
  - Call an API
  - Calculator (because LLMs aren't great at math)
  - Code interpreter (running code on the fly)

## How to call tools (OpenAI Function/Tool Call)

- Introduced by OpenAI in XXX
- Tools are provided as functions
- Option for the LLM to decide when to call the tool

## How to call tools (OpenAI Function/Tool Call)

```{.python code-line-numbers="|1|3-10|12-17"}
from agents import Agent, function_tool

@function_tool
def get_bytes_cafe_menu(date: str) -> any:
    """Returns the menu for the Bytes Cafe for the date provided."""
    return { f"{date}": {
            "daily byte": {
                "name": "Steak Quesadilla", "price": 12, "description": "Flank steak, mixed cheese in a flour tortilla served with air fried potatoes, sour cream and salsa",
            },
        } }

cafe_agent = Agent(
    name="Cafe Agent",
    instructions="You help students locate and provide information about the Bytes Cafe.",
    tools=[
        get_bytes_cafe_menu,
    ])
```

## How to call tools (OpenAI Function/Tool Call)

```{.python code-line-numbers="|1|3|5-15"}
from agents import Agent, FileSearchTool

VECTOR_STORE_ID = "vs_6896d8c959008191981d645850b42313"

building_agent = Agent(
    name="Building Agent",
    instructions="You help students locate and provide information about buildings and rooms on campus. Be descriptive when giving locations.",
    tools=[
        FileSearchTool(
            max_num_results=3,
            vector_store_ids=[VECTOR_STORE_ID],
            include_search_results=True,
        )
    ],
)
```

## How to call tools (Model Context Protocol)

- OpenAI's tool/function calling works if you have local access to the tools
- But how about external systems?
  - e.g., Access to calendar, other systems, hardware, etc.
- You could build local tools to call APIs
- MCP: Model Context Protocol
- Released by Anthropic in XXX
- More details: https://modelcontextprototcol.io

# Next Steps

## How might agents be useful for your own project?

- How could your project benefit?
- What might be some of the challenges to overcome?

## Explore resources

- Code here: TBD
- Modify by adding a new agent to it.
- Create your own use case/agent in the Gradio interface
- Link to resources page / QR Code here: TBD